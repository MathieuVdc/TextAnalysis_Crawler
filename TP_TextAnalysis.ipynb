{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT ANALYSIS & INFORMATION RETRIEVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathieu VANDECASTEELE - M2 SID Janv. 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Université de Rouen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TP est à destination de Pierre Héroux, enseignant-chercheur à l'université de Rouen. Il se décompose en deux parties : l'implémentation d'un système d'Information Retrieval dans un premier temps et la classification de textes dans un second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel des Consignes : \n",
    "* Implanter un crawler, permettant d'extraire récursivement une liste d'URL à partir d'une liste de germes\n",
    "* Extraire le vocabulaire utilisé par un ensemble de documents pour lesquels on dispose d'une liste d'URL\n",
    "* Fournir une représentation vectorielle de chacun des documents précédents basé sur le vocabulaire extrait\n",
    "* Proposez les 10 premiers documents d'une liste ordonnées sur la base d'un score de correspondance entre requête et document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urlreq\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,  CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions codées pour cette partie de TP\n",
    "\n",
    "def get_urls_from_a_webpage(url):\n",
    "    \"\"\"\n",
    "        Retourne tous les URLs intéressants d'une page Wikipédia française\n",
    "    \"\"\"\n",
    "    url_list = []\n",
    "    html_page = urlreq.urlopen(url)\n",
    "    soup = BeautifulSoup(html_page)\n",
    "    for link in soup.findAll('a'):\n",
    "        temp = link.get('href')\n",
    "        # On s'assure que le lien soit correct, qu'il redirige vers une page externe et non un fichier.\n",
    "        if temp and temp[0] == '/': \n",
    "            if temp[1]=='/':\n",
    "                url = \"https:\"+temp\n",
    "            else : \n",
    "                url = \"https://fr.wikipedia.org\"+temp\n",
    "            if not (url[len(url)-3:len(url)]=='jpg' or url[len(url)-10:len(url)-3]=='section' or url[len(url)-9:len(url)-2]=='section' or url == 'https://fr.wikipedia.org/wiki/Cat%C3%A9gorie:Article_avec_une_section_vide_ou_incompl%C3%A8te'):\n",
    "                url_list.append(url)\n",
    "    return (np.unique(url_list)).tolist()\n",
    "  \n",
    "    \n",
    "def get_full_list_urls(start_url_list):\n",
    "    \"\"\"\n",
    "        Retourne tous les URLs d'une liste de germes\n",
    "    \"\"\"        \n",
    "    final_list = []\n",
    "    \n",
    "    for start_url in start_url_list:\n",
    "        \n",
    "        leveltwo = []\n",
    "        print('Exploring... '+str(start_url))\n",
    "        leveltwo.extend(get_urls_from_a_webpage(start_url))\n",
    "        \n",
    "        final_list.append(start_url)\n",
    "        final_list.extend(leveltwo)\n",
    "       \n",
    "    return (np.unique(final_list)).tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_webpage_raw_text(url):\n",
    "    \"\"\"\n",
    "        Crée un dictionnaire du contenu d'une page web.\n",
    "    \"\"\"\n",
    "    dic = {}\n",
    "    dic['title'] = []\n",
    "    dic['url']= [url]\n",
    "    dic['subtitles'] = []\n",
    "    dic['content'] = []\n",
    "    \n",
    "    subtitle_tags = ['h2','h3','h4','h5','h6']\n",
    "    \n",
    "    try :\n",
    "        html_page = urlreq.urlopen(url)\n",
    "        soup = BeautifulSoup(html_page)\n",
    "        for link in soup.findAll('h1'):\n",
    "            dic['title'].append(link.text)\n",
    "        for tag in subtitle_tags:\n",
    "            for link in soup.findAll(tag):\n",
    "                dic['subtitles'].append(link.text)\n",
    "        dic['content'] = soup.body.text\n",
    "    except :\n",
    "        print(str(url)+' is a non valid URL for parsing')\n",
    "    finally :\n",
    "        return dic\n",
    "\n",
    "\n",
    "def get_text_cleaned(raw_text):\n",
    "    \"\"\"\n",
    "        Nettoie le texte passé en entrée. On s'assure de retirer toutes les ponctuations, les majuscules, les espaces en trop et on s'assure enfin que aucun mots ne sont collés entre eux.\n",
    "    \"\"\"\n",
    "    table = str.maketrans('', '', string.punctuation + '’°“‘”—→»«®©℠↑²™')\n",
    "    cleaned = raw_text.translate(table).lower().rstrip().lstrip()\n",
    "    cleanedplus = cleaned.replace('\\n',' ').replace('\\xa0',' ').replace('\\t',' ').replace('  ',' ')\n",
    "    cleaned_better = cleanedplus.replace('  ',' ').replace('  ',' ').replace('  ',' ').replace('  ',' ')\n",
    "    cleaned_best = cleaned_better.replace('  ',' ').rstrip().lstrip()\n",
    "    return cleaned_best\n",
    "\n",
    "\n",
    "def clean_dic_content(dictionnary):\n",
    "    \"\"\"\n",
    "        Prend un dictionnaire créé d'une page web en entrée et nettoie son contenu.\n",
    "    \"\"\"\n",
    "    text_to_clean = dictionnary['content']\n",
    "    text_cleaned = get_text_cleaned(text_to_clean)\n",
    "    dictionnary['content']=[text_cleaned]\n",
    "    return dictionnary\n",
    "\n",
    "\n",
    "def make_document_dictionnary(url):\n",
    "    \"\"\"\n",
    "        Crée un dictionnaire nettoyé d'une page web.\n",
    "    \"\"\"\n",
    "    dic = get_webpage_raw_text(url)\n",
    "    if ((dic['content'] != []) and (dic != None)):\n",
    "        return clean_dic_content(dic)\n",
    "\n",
    "    \n",
    "def make_a_Query(query, text_list):\n",
    "    \"\"\"\n",
    "        Permet de faire une requête. Plusieurs étapes : Bag fo Words pour chaque document + TFIDF + calcul du score avec un dot product.\n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorizer.fit(text_list)\n",
    "    \n",
    "    score = -tfidf_vectorizer.transform(text_list) * tfidf_vectorizer.transform(query).T.toarray().sum(axis = 1)\n",
    "    rank = 0\n",
    "                                        \n",
    "    for i in (np.argsort(score)[0:10]):\n",
    "        rank = rank+1\n",
    "        print(str(rank)+\"-> \"+str(url_list[i])+\" , score de : %.2f\" % (-score[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit une liste d'URL de base comme étant les germes de notre crawler. Pour économiser du temps de calcul nous n'allons prendre que 2 URLS : un axé histoire et un autre axé informatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = []\n",
    "liste.append(\"https://fr.wikipedia.org/wiki/Cinqui%C3%A8me_R%C3%A9publique_(France)\")\n",
    "liste.append(\"https://fr.wikipedia.org/wiki/Bill_Gates\")\n",
    "\n",
    "url_list = get_full_list_urls(liste)\n",
    "print(len(url_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous créons les dictionnaires et nous les stockons dans une liste : certaines pages ne peuvent pas être parsées et par conséquent nous retournons des erreurs dans ces situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fr.wikipedia.org/wiki/Wikipédia:Contact is a non valid URL for parsing\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "for url in url_list:\n",
    "    doc_list.append(make_document_dictionnary(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a supprimer : 787\n"
     ]
    }
   ],
   "source": [
    "# Récupérer chaque contenu dans une liste :\n",
    "# L'idée est d'abord de nettoyer la liste de dictionnaire et de s'assurer qu'il n'y a pas de dictionnaires vides ou de dictionnaires possédant un contenu vide. \n",
    "# Le parsing des pages web n'est pas tout le temps parfait.\n",
    "# Si il y a un problème, un indice de dictionnaire à supprimer dans la liste des URLs est retourné.\n",
    "cleaned_doc_list = []\n",
    "indice = 0\n",
    "for doc in doc_list :\n",
    "    if (doc != None):\n",
    "        cleaned_doc_list.append(doc)\n",
    "        indice = indice+1\n",
    "    else :\n",
    "        print(\"a supprimer : \"+str(indice))\n",
    "        indice = indice+1\n",
    "        \n",
    "# Nous supprimons l'élément d'indice 787.       \n",
    "#del doc_list[787]\n",
    "\n",
    "        \n",
    "# Nous créons un vecteur de textes où chaque élément est donc un des textes correspondant à un URL. \n",
    "texts_list = []\n",
    "for doc in cleaned_doc_list :\n",
    "    try :\n",
    "        if (doc['content'] != None) and (doc['url'] != None):\n",
    "            texts_list.append(doc['content'][0])\n",
    "    except :\n",
    "        print(str(doc)+\"Erreur Document Vide\")\n",
    "        \n",
    "# à la fin nous devons avoir un dictionnaire nettoyé de textes et une liste d'URL de même taille et ordonnés de la même façon !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons deux requêtes d'essai :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat : Informatique\n",
      "1-> https://fr.wikipedia.org/wiki/Cat%C3%A9gorie:Portail:Informatique/Articles_li%C3%A9s , score de : 0.40\n",
      "2-> https://fr.wikipedia.org/wiki/Informatique , score de : 0.23\n",
      "3-> https://fr.wikipedia.org/wiki/Informaticien , score de : 0.19\n",
      "4-> https://fr.wikipedia.org/wiki/Portail:Logiciel , score de : 0.17\n",
      "5-> https://fr.wikipedia.org/wiki/1975_en_informatique , score de : 0.15\n",
      "6-> https://fr.wikipedia.org/wiki/1985_en_informatique , score de : 0.15\n",
      "7-> https://fr.wikipedia.org/wiki/Interpr%C3%A8te_(informatique) , score de : 0.11\n",
      "8-> https://fr.wikipedia.org/wiki/Logiciel , score de : 0.09\n",
      "9-> https://fr.wikipedia.org/wiki/Programmation_informatique , score de : 0.08\n",
      "10-> https://fr.wikipedia.org/wiki/British_Computer_Society , score de : 0.07\n",
      "\n",
      "Résultat : Charles de Gaulle\n",
      "1-> https://fr.wikipedia.org/wiki/Charles_de_Gaulle , score de : 1.11\n",
      "2-> https://fr.wikipedia.org/wiki/Crise_de_mai_1958 , score de : 0.78\n",
      "3-> https://fr.wikipedia.org/wiki/Gouvernement_provisoire_de_la_R%C3%A9publique_fran%C3%A7aise , score de : 0.69\n",
      "4-> https://fr.wikipedia.org/wiki/Histoire_de_France_sous_la_Cinqui%C3%A8me_R%C3%A9publique , score de : 0.68\n",
      "5-> https://fr.wikipedia.org/wiki/Michel_Debr%C3%A9 , score de : 0.66\n",
      "6-> https://fr.wikipedia.org/wiki/Georges_Pompidou , score de : 0.65\n",
      "7-> https://fr.wikipedia.org/wiki/Maison_cap%C3%A9tienne_de_Bourbon , score de : 0.65\n",
      "8-> https://fr.wikipedia.org/wiki/Discours_de_Bayeux , score de : 0.64\n",
      "9-> https://fr.wikipedia.org/wiki/Pr%C3%A9sident_de_la_R%C3%A9publique_fran%C3%A7aise , score de : 0.64\n",
      "10-> https://fr.wikipedia.org/w/index.php?title=Cinqui%C3%A8me_R%C3%A9publique_(France)&printable=yes , score de : 0.63\n"
     ]
    }
   ],
   "source": [
    "query = \"Informatique\".split(\" \")   \n",
    "print('Résultat : ' + \" \".join(query))\n",
    "make_a_Query(query,texts_list)    \n",
    "\n",
    "print('')\n",
    "query = \"Charles de Gaulle\".split(\" \")\n",
    "print('Résultat : ' + \" \".join(query))\n",
    "make_a_Query(query,texts_list)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces résultats sont plutôt satisfaisants. Ils pourraient néanmoins être améliorés avec un nettoyage différent, l'utilisation de Lemmes ou encore avec + de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai également dans les dictionnaires penser à stocker séparemment les titres et sous titres des pages, il serait sûrement possible d'améliorer les résultats en appliquant une pondération plus important sur les mots de ces derniers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Illustrez l'adéquation d'un ensemble de documents avec la loi de Zipf\n",
    "* Utiliser découper un corpus multi-lingue en une base de d'apprentissage et une base de test et proposez un classifieur pour la reconnaissance de la langue.\n",
    "* Entraînez sur un corpus un modèle génératif de texte déterminant la probabilité d'un mot sachant le précédent. Utilisez-le pour générer des séquences à partir d'un terme. \n",
    "* Chaque nouveau mot wt de la séquence devra être généré aléatoirement avec une probabilité égale à P(wt|wt−1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La loi de Zipf est une observation empirique concernant la fréquence des mots dans un texte. En général, il est dit que les stop words, c'est à dire les mots les plus courants dans une langue sont exponentiellement beaucoup plus fréquents que les autres mots. Illustrons là avec un ensemble de documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j'importe le corpus reuters et crée une liste de tuples (mots, occurences)\n",
    "reuters_words = [w.lower() for w in reuters.words()]\n",
    "words = set(reuters_words)\n",
    "counts = [(w, reuters_words.count(w)) for w in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720901\n"
     ]
    }
   ],
   "source": [
    "# Nombre de mots dans le corpus :\n",
    "print(len(reuters.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# je la trie dans l'ordre décroissant\n",
    "sorted_data = sorted(counts, key=lambda tup:(-tup[1], tup[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 94687),\n",
       " (',', 72360),\n",
       " ('the', 69277),\n",
       " ('of', 36779),\n",
       " ('to', 36400),\n",
       " ('in', 29253),\n",
       " ('and', 25648),\n",
       " ('said', 25383),\n",
       " ('a', 25103),\n",
       " ('mln', 18623),\n",
       " ('s', 15680),\n",
       " ('vs', 14341),\n",
       " ('for', 13782),\n",
       " ('-', 13705),\n",
       " ('dlrs', 12417)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La loi semble être valide ici, traçons la courbe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_zipf = [tup[0] for tup in sorted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences_zipf = [tup[1] for tup in sorted_data]\n",
    "word_number = 1720901\n",
    "frequences_zipf = [x / word_number for x in occurences_zipf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.055021758950689205,\n",
       " 0.042047741270415905,\n",
       " 0.040256237866094564,\n",
       " 0.021371944115320986,\n",
       " 0.021151710644598382,\n",
       " 0.016998653612264738,\n",
       " 0.014903820731117014,\n",
       " 0.014749831628896723,\n",
       " 0.014587126162399813,\n",
       " 0.010821656794899881]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequences_zipf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b5de780>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(words_zipf[0:30],frequences_zipf[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque bien cette différence fréquentielles qui a l'allure d'une courbe exponentielle, on valide donc la théorie de Zipf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maintenant**, faisons une classification de langages. J'ai choisi de classer des langues latines car NLTK possède déjà pas mal de données à utiliser dans ces langues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Swedish_Svenska-Latin1': 121,\n",
       " 'Portuguese_Portugues-Latin1': 80,\n",
       " 'English-Latin1': 67,\n",
       " 'German_Deutsch-Latin1': 60,\n",
       " 'Spanish_Espanol-Latin1': 58,\n",
       " 'French_Francais-Latin1': 57,\n",
       " 'Italian_Italiano-Latin1': 51}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On récupère les données via le corpus udhr :\n",
    "languages = ['Portuguese_Portugues-Latin1', 'Swedish_Svenska-Latin1','French_Francais-Latin1','English-Latin1','German_Deutsch-Latin1','Spanish_Espanol-Latin1','Italian_Italiano-Latin1']\n",
    "dataX = []\n",
    "datay = []\n",
    "for language in languages :\n",
    "    text = nltk.corpus.udhr.sents(language)\n",
    "    for sentences in text:\n",
    "        dataX.append(\" \".join(sentences))\n",
    "        datay.append(language)\n",
    "        \n",
    "def most_popular_elements_in_list(list_to_top, number_wanted):\n",
    "    return dict(Counter(list_to_top).most_common(number_wanted))\n",
    "\n",
    "most_popular_elements_in_list(datay,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que le suédois et le portugais sont + présents que les autres langues mais on ne peut parler réellement de sur-représentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On split les données en faisant un dataset d'entraînement et un autre de test. Nous ferons de la **crossvalidation** pour valider et généraliser le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataX,datay,test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je choisis d'utiliser une représentation Bag Of Words avec TF-IDF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "             English-Latin1       1.00      0.96      0.98        28\n",
      "     French_Francais-Latin1       1.00      0.96      0.98        23\n",
      "      German_Deutsch-Latin1       1.00      1.00      1.00        11\n",
      "    Italian_Italiano-Latin1       1.00      1.00      1.00        14\n",
      "Portuguese_Portugues-Latin1       1.00      0.71      0.83        35\n",
      "     Spanish_Espanol-Latin1       1.00      1.00      1.00        14\n",
      "     Swedish_Svenska-Latin1       0.76      1.00      0.87        39\n",
      "\n",
      "                  micro avg       0.93      0.93      0.93       164\n",
      "                  macro avg       0.97      0.95      0.95       164\n",
      "               weighted avg       0.94      0.93      0.93       164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train_tf = vectorizer.transform(X_train)\n",
    "X_test_tf = vectorizer.transform(X_test)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "parameters = {'alpha':[1]}\n",
    "gs = GridSearchCV(classifier, parameters, cv = 5)\n",
    "gs.fit(X_train_tf,y_train)\n",
    "\n",
    "confusion_matrix(y_test,gs.predict(X_test_tf))\n",
    "print(classification_report(y_test,gs.predict(X_test_tf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons des très bons résultats avec de la CrossValidation et TF-IDF. Ces résultats peuvent sûrement être supérieurs avec un autre classifieur comme par exemple un SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dernier point, faire de la génération de texte à partir d'un mot précédent :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est typiquement sur une utilisation d'un modèle Bi-Gram, je me suis inspiré d'un code de **Yann Soulard** pour implémenter cela avec la Déclaration Universelle des droits de l'Homme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Générations : \n",
      "\n",
      "Articlepremier Tous sont doués de maladie , la femme , en droits et à un salaire égal et ont proclamé à la même protection de faire partie d ' homme Préambule Considérant que les garanties nécessaires ; cette volonté . \n",
      "\n",
      "\n",
      "Article15 Tout individu a droit à l ' Organisation des droits et de son bien - fondé de sa famille , ni du droit à des conditions de l ' exprimer par l ' homme ne sera l ' ordre national et ceux de poursuites réellement fondées sur le logement , de la traite des agissements contraires aux principes des Nations Unies , de conscience et de faire partie d ' égalité , l ' homme et satisfaisantes de s ' Etat . \n",
      "\n",
      "\n",
      "Article16 A partir de raison et complétée , tant en commun à sa famille , il est l ' un monde , sans aucune distinction à la liberté et celui de barbarie qui lui sont engagés à favoriser le droit à la dignité et de toutes leurs droits de pensée , Considérant qu ' homme soient nés dans le cas de ses moyens de changer de réunion et plein consentement des droits fondamentaux de poursuites réellement fondées sur le fondement de droit à l ' intermédiaire de meilleures conditions de la paix dans les populations des conditions équitables et tous les droits et à la coopération internationale , détenu ni en coopération internationale , soit par l ' une liberté du mariage ou hors mariage et en tous les êtres humains seront libres et au libre et culturels indispensables à sa vie dans les organes de couleur , de l ' immixtions ou omissions qui implique le fondement de fonder une telle discrimination . \n",
      "\n",
      "\n",
      "Nulne sera infligé aucune restriction quant à la loi . \n",
      "\n",
      "\n",
      "L' organisation et lors de ces droits et à ce que celle qui décidera , non autonome ou territoire dont une égale protection de la justice et de l ' association pacifiques . \n",
      "\n",
      "\n",
      "Toutepersonne a droit à la dignité humaine et ceux de leurs droits égaux devant la liberté de ses droits égaux au suffrage universel égal pour que la personne a le progrès social et de sa famille est ressortissante , tant en d ' en suprême recours , dans le culte et à sa santé , de changer de protection de la protection de manifester sa famille , la présente Déclaration universelle des peines ou dans son pays . \n",
      "\n",
      "\n",
      "Article23 Toute personne a droit sans aucune , ni d ' application universelles et libertés est essentiel d ' homme ont été assurées . \n",
      "\n",
      "\n",
      "L' éducation , de droit , l ' esprit de la présente Déclaration universelle des peines ou omissions qui violerait la reconnaissance de conscience de nationalité , de raison et la dignité humaine , de maladie , à sa dignité inhérente à un procès public qu ' habillement , qu ' acte délictueux d ' Etat . \n",
      "\n",
      "\n",
      "Demême protection sociale , l ' homme ont droit de sa volonté . \n",
      "\n",
      "\n",
      "L' effort national et satisfaisantes de conviction ainsi qu ' association pacifiques . \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieuvdc/.virtualenvs/textA/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "texte = nltk.corpus.udhr.words('French_Francais-Latin1')\n",
    "dataX = []\n",
    "for sents in texte:\n",
    "    dataX.append(sents)\n",
    "      \n",
    "def compute_transition_matrix(seq):\n",
    "    \"\"\" Function for computing the transition matrix between characters for a given sequence in input. \"\"\"\n",
    "    unique_states = np.unique(seq)\n",
    "    nb_states = len(unique_states)\n",
    "\n",
    "    A = np.zeros((nb_states+1, nb_states+1)) # +1 = an additional state for beginning or ending a sentence.\n",
    "    # count the transitions\n",
    "    for i in range(len(seq)-1):\n",
    "\n",
    "        if seq[i] in ['.', '!', '?']:\n",
    "            A[np.where(unique_states == seq[i]), -1] += 1\n",
    "            if seq[i+1]==' ' and i+2<len(seq): # If this is a space, we focus on the next character\n",
    "                A[-1, np.where(unique_states == seq[i + 2])] += 1\n",
    "                i += 1\n",
    "            else:\n",
    "                A[-1, np.where(unique_states == seq[i + 1])] += 1\n",
    "        else:\n",
    "            A[np.where(unique_states == seq[i]), np.where(unique_states == seq[i + 1])] += 1\n",
    "    # normalization\n",
    "    for i in range(nb_states+1):\n",
    "        norm = A[i,:].sum()\n",
    "        A[i,:] /= norm\n",
    "    return A\n",
    "\n",
    "\n",
    "def generate_sequences(set_states, A, N):\n",
    "    \"\"\" Generate N sequences using the transition matrix A and according to the possible states defined in set_states \"\"\"\n",
    "\n",
    "    list_seq_gen = []\n",
    "    for i in range(N):\n",
    "\n",
    "        seq_gen = ''\n",
    "        elmt_gen = np.random.choice(set_states, p=A[-1,:-1]) # first term\n",
    "        index_elmt = int(np.where(set_states==elmt_gen)[0])\n",
    "        seq_gen += elmt_gen\n",
    "        while elmt_gen not in ['.', '!', '?']:\n",
    "            #print(elmt_gen, index_elmt)\n",
    "            elmt_gen = np.random.choice(set_states, p=A[index_elmt,:-1])\n",
    "            index_elmt = int(np.where(set_states == elmt_gen)[0])\n",
    "            seq_gen += elmt_gen+\" \"\n",
    "\n",
    "        list_seq_gen.append(seq_gen)\n",
    "\n",
    "    return list_seq_gen\n",
    "\n",
    "\n",
    "unique_states = np.unique(dataX)\n",
    "\n",
    "# Modélisation avec la matrice de transition.\n",
    "transitions = compute_transition_matrix(dataX)\n",
    "\n",
    "# Générons les phrases :\n",
    "n = 10\n",
    "generated_sequences = generate_sequences(unique_states, transitions, n)\n",
    "\n",
    "print(\"Générations : \\n\")\n",
    "for gen_sequence in generated_sequences:\n",
    "    print((gen_sequence+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour conclure** sur cette génération de textes, on se rend vite compte que c'est imparfait du fait de l'utilisation uniquement du mot précédent. Il faudrait tester avec plus qu'un seul et les résultats seront sûrement meilleurs. Les résultats actuels restent quand même relativement satisfaisants."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
